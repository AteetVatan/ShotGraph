# ShotGraph Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# Execution Profile
# =============================================================================
# Execution profile: debug_cpu or prod_gpu
# - debug_cpu: Uses mock services (fast, no GPU required, suitable for debugging)
# - prod_gpu: Uses real AI models (requires GPU and full ML dependencies)
EXECUTION_PROFILE=debug_cpu

# Enable GPU support (requires nvidia-docker for Docker)
# Set to false for debugging on CPU-only systems (16GB RAM recommended)
# When false, the system will use mock services even if GPU is detected
GPU_ENABLED=false

# =============================================================================
# LLM Configuration
# =============================================================================
# LLM provider: together, groq, or local
LLM_PROVIDER=together

# LLM API key (required for together/groq providers)
LLM_API_KEY=your_api_key_here

# LLM model identifier
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3

# Enable parallel LLM calls for shot planning
LLM_PARALLEL=false

# Together.ai API base URL
LLM_TOGETHER_BASE_URL=https://api.together.xyz/v1

# Groq API base URL
LLM_GROQ_BASE_URL=https://api.groq.com/openai/v1

# Together.ai API request timeout in seconds (1.0-600.0)
LLM_TOGETHER_TIMEOUT=120.0

# Groq API request timeout in seconds (1.0-600.0)
LLM_GROQ_TIMEOUT=60.0

# Maximum tokens for LLM responses (256-32768)
LLM_MAX_TOKENS=4096

# =============================================================================
# Video Generation
# =============================================================================
# Video generation model
VIDEO_MODEL=stable-video-diffusion

# Path to video model weights (optional, uses default if empty)
VIDEO_MODEL_PATH=

# Output video resolution (format: WIDTHxHEIGHT)
VIDEO_RESOLUTION=1024x576

# Output video FPS (1-60)
VIDEO_FPS=24

# Default shot duration in seconds (1.0-30.0)
DEFAULT_SHOT_DURATION=5.0

# Video codec for encoding
VIDEO_CODEC=libx264

# Audio codec for encoding
VIDEO_AUDIO_CODEC=aac

# Fade transition duration in seconds (0.0-2.0)
VIDEO_TRANSITION_DURATION=0.5

# Subtitle font size in pixels (12-72)
VIDEO_SUBTITLE_FONTSIZE=36

# Use frame interpolation for smoother transitions
VIDEO_USE_FRAME_INTERPOLATION=false

# Number of frames to interpolate between shots (1-16)
VIDEO_INTERPOLATION_FRAMES=4

# Enable Ken Burns (pan/zoom) effect for still images
VIDEO_KEN_BURNS_ENABLED=true

# Maximum zoom amount for Ken Burns effect (0.0-0.5)
VIDEO_KEN_BURNS_ZOOM_RANGE=0.2

# =============================================================================
# TTS Configuration
# =============================================================================
# Edge TTS voice identifiers (cloud-based, free, works on CPU/GPU)
# List available voices: python -m edge_tts --list-voices
# English voice ID (Edge TTS format: lang-region-nameNeural)
TTS_VOICE_EN=en-US-AriaNeural

# Hindi voice ID (Edge TTS format: lang-region-nameNeural)
TTS_VOICE_HI=hi-IN-SwaraNeural

# =============================================================================
# Music Generation
# =============================================================================
# Music generation model (HuggingFace model name)
# Options: musicgen-small, musicgen-medium, musicgen-large, or full path like facebook/musicgen-*
# If no "/" in model name, MUSIC_MODEL_ORG prefix will be added
MUSIC_MODEL=musicgen-medium

# HuggingFace organization/prefix for music model
# Default: facebook (for facebook/musicgen-* models)
MUSIC_MODEL_ORG=facebook

# Maximum duration per music generation segment in seconds (1.0-30.0)
MUSIC_MAX_SEGMENT_DURATION=12.0

# Background music volume (0.0-1.0)
MUSIC_VOLUME=0.3

# Music volume during narration (ducking level, 0.0-1.0)
MUSIC_DUCK_LEVEL=0.2

# Duration of crossfade between scene music tracks in seconds (0.0-5.0)
MUSIC_CROSSFADE_DURATION=1.0

# =============================================================================
# Storage Paths
# =============================================================================
# Output storage path
STORAGE_PATH=./output

# Assets directory path
ASSETS_PATH=./assets

# =============================================================================
# Retry Configuration
# =============================================================================
# Maximum retry attempts per agent (0-5)
MAX_RETRIES=2

# =============================================================================
# Experimental Features
# =============================================================================
# Use TOON format for LLM communication (experimental)
USE_TOON_FORMAT=false

# =============================================================================
# Security
# =============================================================================
# Enable API key authentication (recommended for production)
API_KEY_ENABLED=false

# API key for authentication (generate a secure random string)
API_KEY=your_secure_api_key_here

# Rate limit: maximum requests per minute per client
RATE_LIMIT_PER_MINUTE=10

# Maximum story length in characters
MAX_STORY_LENGTH=100000

# Maximum story size in bytes (UTF-8 encoded)
MAX_STORY_SIZE_BYTES=500000

# CORS origins (JSON array format, empty array = disabled)
# Example: CORS_ORIGINS=["http://localhost:3000","https://yourdomain.com"]
# Leave empty array [] to disable CORS
CORS_ORIGINS=[]