# ShotGraph Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# Execution Profile
# =============================================================================
# debug_cpu: Uses mock services (fast, no GPU required, suitable for debugging)
# prod_gpu: Uses real AI models (requires GPU and full ML dependencies)
EXECUTION_PROFILE=debug_cpu
GPU_ENABLED=false

# =============================================================================
# LLM Configuration - Together AI (Required)
# =============================================================================
# Together AI API key (required)
LLM_API_KEY=your_api_key_here

# Fallback model (used if per-stage models not configured)
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3

# Enable parallel LLM calls for shot planning
LLM_PARALLEL=false

# =============================================================================
# Per-Stage Model Configuration (Cost-Optimized Routing)
# =============================================================================
# Step A - Story compression (cheapest: $0.02/$0.04 per 1M tokens)
LLM_MODEL_STORY_COMPRESS=google/gemma-3n-E4B-it
LLM_MODEL_STORY_COMPRESS_FALLBACK=meta-llama/Llama-3.2-3B-Instruct-Turbo

# Step B - Scene breakdown ($0.18/$0.18 per 1M tokens)
LLM_MODEL_SCENE_DRAFT=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
LLM_MODEL_SCENE_DRAFT_LARGE=meta-llama/Llama-4-Scout-17B-16E-Instruct

# Step C - Shot planning ($0.27/$0.85 per 1M tokens)
LLM_MODEL_SHOT_FINAL=meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
LLM_MODEL_SHOT_FINAL_FALLBACK=meta-llama/Llama-3.3-70B-Instruct-Turbo

# Step D - JSON repair ($0.06/$0.06 per 1M tokens)
LLM_MODEL_JSON_REPAIR=meta-llama/Llama-3.2-3B-Instruct-Turbo

# Safety/moderation
LLM_SAFETY_MODEL=meta-llama/Llama-Guard-4-12B

# Cost control thresholds
LLM_SKIP_SUMMARIZATION_THRESHOLD=2000
LLM_USE_LARGE_CONTEXT_THRESHOLD=8000

# =============================================================================
# Video Generation
# =============================================================================
VIDEO_MODEL=stable-video-diffusion
VIDEO_RESOLUTION=1024x576
VIDEO_FPS=24
DEFAULT_SHOT_DURATION=5.0

# =============================================================================
# TTS Configuration
# =============================================================================
# Edge TTS voices (cloud-based, free)
TTS_VOICE_EN=en-US-AriaNeural
TTS_VOICE_HI=hi-IN-SwaraNeural

# =============================================================================
# Music Generation
# =============================================================================
# Note: On CPU, model auto-downgrades to musicgen-small for memory safety
MUSIC_MODEL=musicgen-medium
MUSIC_MODEL_ORG=facebook
MUSIC_MAX_SEGMENT_DURATION=12.0
MUSIC_VOLUME=0.3
MUSIC_DUCK_LEVEL=0.2
MUSIC_CROSSFADE_DURATION=1.0

# =============================================================================
# HuggingFace Configuration
# =============================================================================
# HuggingFace token for authenticated model access (optional, for gated models)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=

# HuggingFace cache directory (optional, uses default ~/.cache/huggingface if empty)
# Set this to use a custom location for model cache
HF_HOME=

# =============================================================================
# Storage Paths
# =============================================================================
STORAGE_PATH=./output
ASSETS_PATH=./assets

# =============================================================================
# Retry Configuration
# =============================================================================
MAX_RETRIES=2

# =============================================================================
# Experimental Features
# =============================================================================
# TOON format reduces token usage by ~40% (enabled by default)
USE_TOON_FORMAT=true

# =============================================================================
# Security (Optional)
# =============================================================================
API_KEY_ENABLED=false
API_KEY=your_secure_api_key_here
RATE_LIMIT_PER_MINUTE=10

# =============================================================================
# Advanced Configuration (Optional - uses defaults if not set)
# =============================================================================
# Maximum story length in characters
MAX_STORY_LENGTH=100000

# Maximum story size in bytes (UTF-8 encoded)
MAX_STORY_SIZE_BYTES=500000

# CORS origins (JSON array format, empty array = disabled)
# Example: CORS_ORIGINS=["http://localhost:3000","https://yourdomain.com"]
CORS_ORIGINS=[]

# Advanced LLM settings (optional - uses defaults)
# LLM_TOGETHER_BASE_URL=https://api.together.xyz/v1
# LLM_TOGETHER_TIMEOUT=120.0
# LLM_MAX_TOKENS=4096

# Advanced video settings (optional - uses defaults)
# VIDEO_CODEC=libx264
# VIDEO_AUDIO_CODEC=aac
# VIDEO_TRANSITION_DURATION=0.5
# VIDEO_SUBTITLE_FONTSIZE=36
# VIDEO_USE_FRAME_INTERPOLATION=false
# VIDEO_INTERPOLATION_FRAMES=4
# VIDEO_KEN_BURNS_ENABLED=true
# VIDEO_KEN_BURNS_ZOOM_RANGE=0.2
